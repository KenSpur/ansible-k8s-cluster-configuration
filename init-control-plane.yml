- name: Stage 1 - Initialize Control Plane
  hosts: control_plane
  gather_facts: yes
  become: true
  vars:
    pod_network_cidr: "{{ pod_network_cidr }}"

  tasks:
  - name: Check if Kubernetes control plane is initialized
    stat:
      path: /etc/kubernetes/admin.conf
    register: kubernetes_admin_conf

  - name: Initialize Kubernetes control plane
    shell:
      cmd: |
        kubeadm init \
          --pod-network-cidr="{{ pod_network_cidr }}"
    when: not kubernetes_admin_conf.stat.exists

  - name: Check if kubectl config file exists
    stat:
      path: "{{ ansible_env.HOME }}/.kube/config"
    register: kubectl_config_file

  - name: Get the content of the kubectl config file
    slurp:
      src: "{{ ansible_env.HOME }}/.kube/config"
    register: kubectl_config_content
    when: kubectl_config_file.stat.exists

  - name: Get the content of /etc/kubernetes/admin.conf
    slurp:
      src: /etc/kubernetes/admin.conf
    register: admin_conf_content

  - name: Configure kubectl for the current user
    block:
      - name: Create .kube directory if it doesn't exist
        file:
          path: "{{ ansible_env.HOME }}/.kube"
          state: directory
          mode: '0755'

      - name: Copy /etc/kubernetes/admin.conf to the user's kube config
        copy:
          src: /etc/kubernetes/admin.conf
          dest: "{{ ansible_env.HOME }}/.kube/config"
          remote_src: yes

      - name: Set ownership of the user's kube config
        file:
          path: "{{ ansible_env.HOME }}/.kube/config"
          owner: "{{ ansible_env.USER }}"
          group: "{{ ansible_env.USER }}"
    when: not kubectl_config_file.stat.exists or (kubectl_config_content.content | default(None) | b64decode != admin_conf_content.content | b64decode)

  - name: Install python3-pip & python3-yaml
    apt:
      pkg:
        - python3-pip
        - python3-yaml
      state: present

  - name: Install the openshift Python library
    pip:
      name: openshift
      state: present

  - name: Render tigera-operator.yaml
    template:
      src: files/calico/v3.25.0/manifests/tigera-operator.yaml.j2
      dest: tigera-operator.yaml

  - name: Install Calico Operator
    k8s:
      state: present
      src: tigera-operator.yaml
      kubeconfig: "{{ ansible_env.HOME }}/.kube/config"

  - name: Remove tigera-operator.yaml
    file:
      path: tigera-operator.yaml
      state: absent

  - name: Render custom-resources.yaml
    template:
      src: files/calico/v3.25.0/manifests/custom-resources.yaml.j2
      dest: custom-resources.yaml

  - name: Install Calico Custom Resources
    k8s:
      state: present
      src: custom-resources.yaml
      kubeconfig: "{{ ansible_env.HOME }}/.kube/config"

  - name: Remove custom-resources.yaml
    file:
      path: custom-resources.yaml
      state: absent

  - name: Wait for all calico-system pods to be Running
    k8s_info:
      kind: Pod
      namespace: calico-system
      kubeconfig: "{{ ansible_env.HOME }}/.kube/config"
    register: calico_pods_result
    until: >
      calico_pods_result.resources | map(attribute='status.phase') | unique | length == 1
      and calico_pods_result.resources | map(attribute='status.phase') | first == 'Running'
    retries: 30
    delay: 10

  - name: Generate join command for worker nodes
    shell:
      cmd: kubeadm token create --print-join-command
    register: kubeadm_join_command_result
    no_log: true  # Avoid logging sensitive information

  - name: Set join command fact for worker nodes
    set_fact:
      kubeadm_join_command: "{{ kubeadm_join_command_result.stdout }}"
    no_log: true  # Avoid logging sensitive information
    delegate_to: localhost

  - name: Save join command to a temporary file
    copy:
      content: "{{ kubeadm_join_command }}"
      dest: "/tmp/kubeadm_join_command"
    no_log: true  # Avoid logging sensitive information